{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ce1f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 50., 100.])\n",
      "tensor([[ 50., 150.],\n",
      "        [100., 300.]])\n",
      "tensor([ 50., 100.])\n",
      "tensor([[ 50., 100.],\n",
      "        [150., 300.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.],\n",
      "         [16., 17., 18.]]])\n",
      "tensor([[[[ 1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9.]],\n",
      "\n",
      "         [[10., 11., 12.],\n",
      "          [13., 14., 15.],\n",
      "          [16., 17., 18.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9.]],\n",
      "\n",
      "         [[10., 11., 12.],\n",
      "          [13., 14., 15.],\n",
      "          [16., 17., 18.]]]])\n",
      "tensor([[[[ 1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9.]],\n",
      "\n",
      "         [[ 1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.],\n",
      "          [ 7.,  8.,  9.]]],\n",
      "\n",
      "\n",
      "        [[[10., 11., 12.],\n",
      "          [13., 14., 15.],\n",
      "          [16., 17., 18.]],\n",
      "\n",
      "         [[10., 11., 12.],\n",
      "          [13., 14., 15.],\n",
      "          [16., 17., 18.]]]])\n",
      "tensor([[[[ 1.,  2.,  3.],\n",
      "          [ 1.,  2.,  3.]],\n",
      "\n",
      "         [[ 4.,  5.,  6.],\n",
      "          [ 4.,  5.,  6.]],\n",
      "\n",
      "         [[ 7.,  8.,  9.],\n",
      "          [ 7.,  8.,  9.]]],\n",
      "\n",
      "\n",
      "        [[[10., 11., 12.],\n",
      "          [10., 11., 12.]],\n",
      "\n",
      "         [[13., 14., 15.],\n",
      "          [13., 14., 15.]],\n",
      "\n",
      "         [[16., 17., 18.],\n",
      "          [16., 17., 18.]]]])\n",
      "tensor([[[[ 1.,  1.],\n",
      "          [ 2.,  2.],\n",
      "          [ 3.,  3.]],\n",
      "\n",
      "         [[ 4.,  4.],\n",
      "          [ 5.,  5.],\n",
      "          [ 6.,  6.]],\n",
      "\n",
      "         [[ 7.,  7.],\n",
      "          [ 8.,  8.],\n",
      "          [ 9.,  9.]]],\n",
      "\n",
      "\n",
      "        [[[10., 10.],\n",
      "          [11., 11.],\n",
      "          [12., 12.]],\n",
      "\n",
      "         [[13., 13.],\n",
      "          [14., 14.],\n",
      "          [15., 15.]],\n",
      "\n",
      "         [[16., 16.],\n",
      "          [17., 17.],\n",
      "          [18., 18.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "kpts = torch.tensor([[[1,2,3],[4,5,6],[7,8,9]],[[10,11,12],[13,14,15],[16,17,18]]], dtype=torch.float32)\n",
    "one = kpts.new_tensor(1)\n",
    "ones = kpts.new_tensor([1,3])\n",
    "size0 = torch.stack([one*50,one*100],dim=0)\n",
    "size1 = torch.stack([ones*50,ones*100],dim = 0)\n",
    "size2 = torch.stack([one*50,one*100],dim = 0)\n",
    "size3 = torch.stack([ones*50,ones*100], dim=1)\n",
    "print(size0)\n",
    "print(size1)\n",
    "print(size2)\n",
    "print(size3)\n",
    "\n",
    "print(kpts)\n",
    "a = torch.stack([kpts,kpts],dim = 0)\n",
    "b = torch.stack([kpts,kpts],dim = 1)\n",
    "c = torch.stack([kpts,kpts],dim = 2)\n",
    "d = torch.stack([kpts,kpts],dim = 3)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)    \n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16d7d9",
   "metadata": {},
   "source": [
    "0维张量（标量） -> 1维张量 ....  \n",
    "torch.stack(A,B,dim)，选择在那个维度堆叠A、B  \n",
    "***注***：维度的索引是从0开始的，即第一个维度对应 dim=0，第二个维度对应 dim=1，以此类推。这里kpts虽然只有三个维度，但stack()中的dim是可以取到dim=3的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb42d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5811,  0.9906, -0.4048, -0.8696],\n",
      "         [-1.4755, -0.9574,  1.5655, -2.3737],\n",
      "         [-0.9904, -1.5853,  0.3346, -1.2450]]])\n",
      "tensor([[[[-0.5811,  0.9906, -0.4048, -0.8696],\n",
      "          [-1.4755, -0.9574,  1.5655, -2.3737],\n",
      "          [-0.9904, -1.5853,  0.3346, -1.2450]]]])\n",
      "tensor([[-1.4755, -0.9574,  1.5655, -2.3737],\n",
      "        [-0.9904, -1.5853,  0.3346, -1.2450]])\n",
      "tensor([[-1.4755, -0.9574,  1.5655, -2.3737],\n",
      "        [-0.9904, -1.5853,  0.3346, -1.2450]])\n",
      "torch.Size([1, 3, 1, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([1, 3, 1, 4])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([1, 3, 1, 4])\n",
      "torch.Size([1, 3, 1, 4])\n",
      "torch.Size([1, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(1,3,4)\n",
    "b= a[None,:,:,:]\n",
    "bb = a[0][1:3]\n",
    "bbb = a[0,1:3]\n",
    "e = a.unsqueeze(0)\n",
    "f = a.unsqueeze(1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(bb)\n",
    "print(bbb)\n",
    "x = torch.randn(1,3,1,4)\n",
    "print(x.shape)\n",
    "y = x.squeeze()\n",
    "print(y.shape)\n",
    "z = x.squeeze(0)\n",
    "print(z.shape)\n",
    "q = x.squeeze(1)\n",
    "print(q.shape)\n",
    "p = x.squeeze(2)\n",
    "print(p.shape)\n",
    "r = x.squeeze(3)\n",
    "print(r.shape)\n",
    "t = x.squeeze(-1)\n",
    "print(t.shape)\n",
    "u = x.squeeze(-2)\n",
    "print(u.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5a83c",
   "metadata": {},
   "source": [
    "**逐步索引**：a[][]...  \n",
    "**高级索引**：a[x,y,z,...]  \n",
    "a[None]相当于a[None,:,:,...] 使用索引的方法简便表示维度的增加位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb5ea7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48d10d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "one1 = torch.tensor([1])\n",
    "one2 = torch.tensor(1)\n",
    "print(one1[0]==1)\n",
    "print(one2==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14b48b",
   "metadata": {},
   "source": [
    "tensor([1]) -> 一维的张量 需要索引  \n",
    "tensor(1) -> 0维的标量 不需要索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "30f2cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1477,  0.3213, -0.0311,  0.6991],\n",
      "         [-0.2576, -3.2397, -0.9008,  1.6645],\n",
      "         [-1.4943, -2.3743,  0.5151, -1.3185]],\n",
      "\n",
      "        [[-1.2710,  0.5335, -0.8100, -0.4172],\n",
      "         [-0.0791, -0.2135, -0.1326,  0.1710],\n",
      "         [ 0.6579, -0.7748,  1.0798, -0.4846]]])\n",
      "tensor([[0.6991, 1.6645, 0.5151],\n",
      "        [0.5335, 0.1710, 1.0798]])\n",
      "tensor([[3, 3, 2],\n",
      "        [1, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "size = torch.randn(2,3,4)\n",
    "values, indices = size.max(dim=2)\n",
    "print(size)\n",
    "print(values)  # shape: (2, 1)\n",
    "print(indices)  # shape: (2, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53332f41",
   "metadata": {},
   "source": [
    ".max()返回某一维度的最大值与相应索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f17dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  1.,   2.,   3.,   4.,   5.],\n",
      "          [  6.,   7.,   8.,   9.,  10.],\n",
      "          [ 11.,  12.,  13.,  14.,  15.],\n",
      "          [ 16.,  17.,  18.,  19.,  20.]],\n",
      "\n",
      "         [[ 21.,  22.,  23.,  24.,  25.],\n",
      "          [ 26.,  27.,  28.,  29.,  30.],\n",
      "          [ 31.,  32.,  33.,  34.,  35.],\n",
      "          [ 36.,  37.,  38.,  39.,  40.]],\n",
      "\n",
      "         [[ 41.,  42.,  43.,  44.,  45.],\n",
      "          [ 46.,  47.,  48.,  49.,  50.],\n",
      "          [ 51.,  52.,  53.,  54.,  55.],\n",
      "          [ 56.,  57.,  58.,  59.,  60.]]],\n",
      "\n",
      "\n",
      "        [[[ 61.,  62.,  63.,  64.,  65.],\n",
      "          [ 66.,  67.,  68.,  69.,  70.],\n",
      "          [ 71.,  72.,  73.,  74.,  75.],\n",
      "          [ 76.,  77.,  78.,  79.,  80.]],\n",
      "\n",
      "         [[ 81.,  82.,  83.,  84.,  85.],\n",
      "          [ 86.,  87.,  88.,  89.,  90.],\n",
      "          [ 91.,  92.,  93.,  94.,  95.],\n",
      "          [ 96.,  97.,  98.,  99., 100.]],\n",
      "\n",
      "         [[101., 102., 103., 104., 105.],\n",
      "          [106., 107., 108., 109., 110.],\n",
      "          [111., 112., 113., 114., 115.],\n",
      "          [116., 117., 118., 119., 120.]]]])\n",
      "tensor([[[[  1.,  21.,  41.],\n",
      "          [  2.,  22.,  42.],\n",
      "          [  3.,  23.,  43.],\n",
      "          [  4.,  24.,  44.],\n",
      "          [  5.,  25.,  45.]],\n",
      "\n",
      "         [[  6.,  26.,  46.],\n",
      "          [  7.,  27.,  47.],\n",
      "          [  8.,  28.,  48.],\n",
      "          [  9.,  29.,  49.],\n",
      "          [ 10.,  30.,  50.]],\n",
      "\n",
      "         [[ 11.,  31.,  51.],\n",
      "          [ 12.,  32.,  52.],\n",
      "          [ 13.,  33.,  53.],\n",
      "          [ 14.,  34.,  54.],\n",
      "          [ 15.,  35.,  55.]],\n",
      "\n",
      "         [[ 16.,  36.,  56.],\n",
      "          [ 17.,  37.,  57.],\n",
      "          [ 18.,  38.,  58.],\n",
      "          [ 19.,  39.,  59.],\n",
      "          [ 20.,  40.,  60.]]],\n",
      "\n",
      "\n",
      "        [[[ 61.,  81., 101.],\n",
      "          [ 62.,  82., 102.],\n",
      "          [ 63.,  83., 103.],\n",
      "          [ 64.,  84., 104.],\n",
      "          [ 65.,  85., 105.]],\n",
      "\n",
      "         [[ 66.,  86., 106.],\n",
      "          [ 67.,  87., 107.],\n",
      "          [ 68.,  88., 108.],\n",
      "          [ 69.,  89., 109.],\n",
      "          [ 70.,  90., 110.]],\n",
      "\n",
      "         [[ 71.,  91., 111.],\n",
      "          [ 72.,  92., 112.],\n",
      "          [ 73.,  93., 113.],\n",
      "          [ 74.,  94., 114.],\n",
      "          [ 75.,  95., 115.]],\n",
      "\n",
      "         [[ 76.,  96., 116.],\n",
      "          [ 77.,  97., 117.],\n",
      "          [ 78.,  98., 118.],\n",
      "          [ 79.,  99., 119.],\n",
      "          [ 80., 100., 120.]]]])\n",
      "torch.Size([2, 4, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个形状为 (2, 3, 4, 5) 的随机张量\n",
    "scores = torch.arange(1,121).view(2, 3, 4, 5).float()\n",
    "print(scores)\n",
    "# 执行 permute 和 reshape 操作\n",
    "scores = scores.permute(0, 2, 3, 1)\n",
    "print(scores)\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d4933",
   "metadata": {},
   "source": [
    "这里的轴（维度）交换，并不改变内存位置，实际上是步长（stride）的交换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7c67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supp_mask:\n",
      " tensor([[[[ True, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False,  True],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True],\n",
      "          [False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False,  True],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[ True, False,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [False,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [False, False, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True, False]]],\n",
      "\n",
      "\n",
      "        [[[False, False,  True],\n",
      "          [False, False,  True],\n",
      "          [False,  True, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True, False, False],\n",
      "          [ True,  True,  True],\n",
      "          [ True, False,  True],\n",
      "          [False,  True, False]],\n",
      "\n",
      "         [[ True,  True,  True],\n",
      "          [ True,  True,  True],\n",
      "          [ True,  True, False],\n",
      "          [ True, False, False],\n",
      "          [ True, False, False]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [ True,  True, False],\n",
      "          [False,  True, False],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False]]]])\n",
      "result:\n",
      " tensor([[[[  0.,  21.,  41.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [  0.,   0.,  43.],\n",
      "          [  0.,  24.,   0.],\n",
      "          [  0.,  25.,   0.]],\n",
      "\n",
      "         [[  6.,   0.,   0.],\n",
      "          [  7.,   0.,  47.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [  9.,  29.,   0.],\n",
      "          [  0.,  30.,  50.]],\n",
      "\n",
      "         [[  0.,  31.,   0.],\n",
      "          [  0.,   0.,  52.],\n",
      "          [  0.,   0.,  53.],\n",
      "          [ 14.,   0.,   0.],\n",
      "          [  0.,   0.,   0.]],\n",
      "\n",
      "         [[ 16.,  36.,  56.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [ 18.,  38.,  58.],\n",
      "          [ 19.,   0.,  59.],\n",
      "          [  0.,   0.,  60.]]],\n",
      "\n",
      "\n",
      "        [[[ 61.,  81.,   0.],\n",
      "          [ 62.,  82.,   0.],\n",
      "          [ 63.,   0., 103.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.]],\n",
      "\n",
      "         [[  0.,  86., 106.],\n",
      "          [  0.,  87., 107.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [  0.,  89.,   0.],\n",
      "          [ 70.,   0., 110.]],\n",
      "\n",
      "         [[  0.,   0.,   0.],\n",
      "          [  0.,   0.,   0.],\n",
      "          [  0.,   0., 113.],\n",
      "          [  0.,  94., 114.],\n",
      "          [  0.,  95., 115.]],\n",
      "\n",
      "         [[ 76.,  96., 116.],\n",
      "          [  0.,   0., 117.],\n",
      "          [ 78.,   0., 118.],\n",
      "          [  0.,   0., 119.],\n",
      "          [  0.,   0., 120.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "scores = torch.arange(1,121).view(2, 3, 4, 5).float()\n",
    "supp_mask = torch.randint(0, 2, scores.shape, dtype=torch.bool)\n",
    "\n",
    "result = torch.where(supp_mask, torch.zeros_like(scores), scores)\n",
    "\n",
    "print(\"supp_mask:\\n\", supp_mask)\n",
    "print(\"result:\\n\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d767c6",
   "metadata": {},
   "source": [
    "类似于三目运算符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11., 12., 13., 14., 15., 16., 17., 18., 19., 20.],\n",
      "         [31., 32., 33., 34., 35., 36., 37., 38., 39., 40.],\n",
      "         [51., 52., 53., 54., 55., 56., 57., 58., 59., 60.]],\n",
      "\n",
      "        [[21., 22., 23., 24., 25., 26., 27., 28., 29., 30.],\n",
      "         [41., 42., 43., 44., 45., 46., 47., 48., 49., 50.],\n",
      "         [61., 62., 63., 64., 65., 66., 67., 68., 69., 70.]]])\n",
      "tensor([13., 35., 57.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_19268\\111152614.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  a = torch.range(1,100).view(10,10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.arange(1,101).view(10,10)\n",
    "k = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "    ])\n",
    "k_transpose = k.T\n",
    "b = a[k.T]\n",
    "c = a[tuple(k.T)]\n",
    "print(b)\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76160b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o0: torch.Size([2, 2])\n",
      "o1: torch.Size([2, 2, 10])\n",
      "o2: torch.Size([2])\n",
      "o3: torch.Size([1, 2, 10])\n",
      "o4: torch.Size([2])\n",
      "tensor([[11, 75],\n",
      "        [32, 48]])\n",
      "tensor([[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "         [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]],\n",
      "\n",
      "        [[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
      "         [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]]])\n",
      "tensor([13, 74])\n",
      "tensor([[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
      "         [50, 51, 52, 53, 54, 55, 56, 57, 58, 59]]])\n",
      "tensor([11, 77])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.arange(0,100).view(10,10)\n",
    "o0 = a[[[[1,7],[3,4]],[[1,5],[2,8]]]]\n",
    "o1 = a[[[1,7],[3,4]],:]\n",
    "o2 = a[([1,7],[3,4])]\n",
    "o3 = a[[[[1,5]]]]\n",
    "o4 = a[[1,7],[1,7]]\n",
    "print(\"o0:\",o0.shape)\n",
    "print(\"o1:\",o1.shape)\n",
    "print(\"o2:\",o2.shape)\n",
    "print(\"o3:\",o3.shape)\n",
    "print(\"o4:\",o4.shape)\n",
    "print(o0)\n",
    "print(o1)\n",
    "print(o2)\n",
    "print(o3)\n",
    "print(o4) \n",
    "s = torch.arange(100).reshape(10, 10)\n",
    "k = torch.tensor([[2, 3], [4, 5], [6, 7]])\n",
    "\n",
    "# 正确用法\n",
    "idx = tuple(k.t())  # (tensor([2,4,6]), tensor([3,5,7]))\n",
    "print(s[idx])  # 输出 tensor([23, 45, 67])\n",
    "\n",
    "# 错误用法\n",
    "print(s[[[2,4,6],[3,5,7]]])  # 会报错或结果不是你想要的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ac2e0",
   "metadata": {},
   "source": [
    "注意要把tensor转换为元组或列表的形式才可以将其识别为批量索引,否则这个tensor会被整个当作第一个维度的索引，而不会对其拆分。列表或元组都会对其内部拆分，然后内部元素分别对应指定的维度的索引，元素为标量则是单个索引，是多维的则是批量索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b95e6371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 6],\n",
      "        [1, 2, 3]])\n",
      "tensor([[1, 0, 1],\n",
      "        [0, 1, 0]])\n",
      "Values2:\n",
      " tensor([[[ 90, 100, 110, 120],\n",
      "         [ 50,  60,  70,  80]],\n",
      "\n",
      "        [[ 95, 105, 115, 125],\n",
      "         [ 55,  65,  75,  85]]])\n",
      "\n",
      "Indices2:\n",
      " tensor([[[2, 2, 2, 2],\n",
      "         [1, 1, 1, 1]],\n",
      "\n",
      "        [[2, 2, 2, 2],\n",
      "         [1, 1, 1, 1]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mat1 = torch.tensor([[1, 5, 3], [4, 2, 6]])\n",
    "values1, idx1 = torch.topk(mat1, k=2, dim=0)\n",
    "print(values1)\n",
    "print(idx1)\n",
    "\n",
    "import torch\n",
    "\n",
    "# 创建一个 3D 张量 (shape: 2x3x4)\n",
    "mat2 = torch.tensor([\n",
    "    [\n",
    "        [10, 20, 30, 40],\n",
    "        [50, 60, 70, 80],\n",
    "        [90, 100, 110, 120]\n",
    "    ],\n",
    "    [\n",
    "        [15, 25, 35, 45],\n",
    "        [55, 65, 75, 85],\n",
    "        [95, 105, 115, 125]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# 沿着 dim=1（即第1维度，行方向）取 top-2\n",
    "values2, idx2 = torch.topk(mat2, k=2, dim=1)\n",
    "\n",
    "print(\"Values2:\\n\", values2)\n",
    "print(\"\\nIndices2:\\n\", idx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8815ad",
   "metadata": {},
   "source": [
    "torch.topk(mat，k，dim)在指定维度上求前k个  \n",
    "**例**：mat.shape 为 (5,6,7)  values, idx = torch.topk(mat,2, 1)  则values 和 idx 的shape 为 (5,***3***,7),values[a][ ***1*** ] [b]索引的结果为在mat[a][:][b]中第 ***1*** 大的数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4ad0dbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 6],\n",
      "        [1, 2, 3]])\n",
      "tensor([[6, 5, 4],\n",
      "        [3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "b = torch.flip(a, dims=[0])\n",
    "print(b)\n",
    "# tensor([[4, 5, 6],\n",
    "#         [1, 2, 3]])  # 沿着行（dim=0）翻转\n",
    "c = torch.flip(a, dims=[0, 1])\n",
    "print(c)\n",
    "# tensor([[6, 5, 4],\n",
    "#         [3, 2, 1]])  # 先翻行，再翻列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74dc0600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 5, 6],\n",
      "        [4, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 输入张量\n",
    "input_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 索引张量\n",
    "index_tensor = torch.tensor([[0, 1, 1], [1, 0, 0]])\n",
    "\n",
    "# 使用 gather 提取数据\n",
    "result = input_tensor.gather(0, index_tensor)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a55aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n",
      "tensor([[-1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn(4,7,9)\n",
    "print(a.shape[:-1])\n",
    "shape0 = a.shape[:-1]\n",
    "b = a.new_full(shape0,-1)\n",
    "print(b)\n",
    "c = a.new_zeros(shape0)\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
